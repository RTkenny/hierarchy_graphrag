{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import datasets\n",
    "from tqdm import tqdm\n",
    "from memorag import Model\n",
    "from functools import partial\n",
    "from functools import partial\n",
    "from transformers.utils import logging\n",
    "from torch.utils.data import DataLoader\n",
    "from longbench_utils import DATASET2CATEGORY, scorer, DATASET2PROMPT, DATASET2MAXNEWTOKENS, makedirs, FileLogger, DefaultDataCollator\n",
    "\n",
    "logger = logging.get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.25it/s]\n",
      "Device set to use cuda:1\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.26it/s]\n",
      "Device set to use cuda\n",
      "2025-01-02 20:08:56,294 - Use pytorch device_name: cuda\n",
      "2025-01-02 20:08:56,295 - Load pretrained SentenceTransformer: /home/rt/data/model/sentence-transformers/multi-qa-mpnet-base-cos-v1\n"
     ]
    }
   ],
   "source": [
    "from hg_rag import BAAIEmbeddingModel, SBertEmbeddingModel, QwenQAModel, QwenSummarizationModel\n",
    "sum_model=QwenSummarizationModel(model_name='/home/rt/data/model/Qwen/Qwen2.5-7B-Instruct'), \n",
    "qa_model=QwenQAModel(model_name='/home/rt/data/model/Qwen/Qwen2.5-7B-Instruct'), \n",
    "# embedding_model=BAAIEmbeddingModel(model_path='/home/rt/data/model/BAAI/bge-m3')\n",
    "emb_model=SBertEmbeddingModel(model_name='/home/rt/data/model/sentence-transformers/multi-qa-mpnet-base-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_longbench(data, indices, tokenizer, max_length=3500, truncate_from_middle=True):\n",
    "    outputs = {'context': [], 'question': [], \"dataset\": [], \"index\": [], \"length\": []}\n",
    "\n",
    "    for input, context, dataset, index in zip(data['input'], data['context'], data['dataset'], indices):\n",
    "        if dataset.endswith(\"_e\"):\n",
    "            dataset = dataset[:-2]\n",
    "\n",
    "        if dataset in ['narrativeqa', 'qasper', 'multifieldqa_en', 'hotpotqa', '2wikimqa', 'musique', 'qmsum']:\n",
    "            question = input\n",
    "        elif dataset == \"gov_report\":\n",
    "            question = \"\"\n",
    "        elif dataset == \"multi_news\":\n",
    "            question = \"\"\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        if max_length is not None:\n",
    "            if truncate_from_middle:\n",
    "                try:\n",
    "                    tokenized_context = tokenizer.encode(context, add_special_tokens=False)\n",
    "                except:\n",
    "                    tokenized_context = tokenizer.encode(context)\n",
    "                if len(tokenized_context) > max_length:\n",
    "                    half = int(max_length / 2)\n",
    "                    context = tokenizer.decode(tokenized_context[:half]) + tokenizer.decode(tokenized_context[-half:])\n",
    "            else:\n",
    "                tokenized_context = tokenizer.encode(context)\n",
    "                context = tokenizer.decode(tokenized_context[-max_length:])\n",
    "\n",
    "        length = len(tokenizer.encode(context))\n",
    "\n",
    "        outputs[\"context\"].append(context)\n",
    "        outputs[\"question\"].append(question)\n",
    "        outputs[\"dataset\"].append(dataset)\n",
    "        outputs[\"index\"].append(index)\n",
    "        outputs[\"length\"].append(length)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./results/longbench/\"\n",
    "\n",
    "dataset_names = ['hotpotqa',] # ['narrativeqa', 'qasper', 'hotpotqa'], ['narrativeqa', 'qasper', 'multifieldqa_en', 'hotpotqa', '2wikimqa', 'musique'] \n",
    "# raw_dataset = datasets.load_dataset(\"json\", data_files=f'/home/rt/data/MemoRAG/THUDM/LongBench/data/{dataset_names[0]}.jsonl', split=\"train\")\n",
    "raw_dataset = datasets.load_dataset(\"json\", data_files='../dataset/TommyChien/MemoRAG-data/longbench.json', split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 100000\n",
    "truncate_from_middle = True\n",
    "\n",
    "process_fn = partial(\n",
    "            process_longbench, \n",
    "            tokenizer=qa_model[0].tokenizer,\n",
    "            max_length=max_length,\n",
    "            truncate_from_middle=truncate_from_middle\n",
    "        )\n",
    "\n",
    "dataset = raw_dataset.map(process_fn, batched=True, num_proc=32, with_indices=True, remove_columns=raw_dataset.column_names)\n",
    "groupby_dataset = dataset.to_pandas().groupby(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 20:15:59,522 - Evaluating hotpotqa (1 / 1)...\n",
      "Generating:   0%|          | 0/200 [00:00<?, ?it/s]2025-01-02 20:15:59,630 - Successfully initialized TreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 50\n",
      "            Summarization Model: <hg_rag.All_Models.QwenSummarizationModel object at 0x7f1c1489a590>\n",
      "            Embedding Models: {'EMB': <hg_rag.All_Models.SBertEmbeddingModel object at 0x7f1c14898820>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2025-01-02 20:15:59,632 - Successfully initialized ClusterTreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 50\n",
      "            Summarization Model: <hg_rag.All_Models.QwenSummarizationModel object at 0x7f1c1489a590>\n",
      "            Embedding Models: {'EMB': <hg_rag.All_Models.SBertEmbeddingModel object at 0x7f1c14898820>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2025-01-02 20:15:59,633 - Successfully initialized RetrievalAugmentation with Config \n",
      "        RetrievalAugmentationConfig:\n",
      "            \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 50\n",
      "            Summarization Model: <hg_rag.All_Models.QwenSummarizationModel object at 0x7f1c1489a590>\n",
      "            Embedding Models: {'EMB': <hg_rag.All_Models.SBertEmbeddingModel object at 0x7f1c14898820>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "            \n",
      "            \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: EMB\n",
      "            Embedding Model: <hg_rag.All_Models.SBertEmbeddingModel object at 0x7f1c14898820>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "            \n",
      "            QA Model: <hg_rag.All_Models.QwenQAModel object at 0x7f1c150048e0>\n",
      "            Tree Builder Type: cluster\n",
      "        \n",
      "2025-01-02 20:15:59,646 - Creating Leaf Nodes\n",
      "2025-01-02 20:16:03,948 - Created 135 Leaf Embeddings\n",
      "2025-01-02 20:16:03,950 - Building All Nodes\n",
      "2025-01-02 20:16:03,954 - Using Cluster TreeBuilder\n",
      "2025-01-02 20:16:03,955 - Constructing Layer 0\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-01-02 20:16:14,648 - Summarization Length: 50\n",
      "2025-01-02 20:16:15,667 - Node Texts Length: 203, Summarized Text Length: 319\n",
      "2025-01-02 20:16:16,717 - Node Texts Length: 441, Summarized Text Length: 555\n",
      "2025-01-02 20:16:17,742 - Node Texts Length: 205, Summarized Text Length: 322\n",
      "2025-01-02 20:16:18,770 - Node Texts Length: 239, Summarized Text Length: 351\n",
      "2025-01-02 20:16:19,798 - Node Texts Length: 261, Summarized Text Length: 372\n",
      "2025-01-02 20:16:20,864 - Node Texts Length: 668, Summarized Text Length: 785\n",
      "2025-01-02 20:16:21,958 - Node Texts Length: 828, Summarized Text Length: 943\n",
      "2025-01-02 20:16:23,032 - Node Texts Length: 637, Summarized Text Length: 754\n",
      "2025-01-02 20:16:24,052 - Node Texts Length: 192, Summarized Text Length: 309\n",
      "2025-01-02 20:16:25,076 - Node Texts Length: 262, Summarized Text Length: 379\n",
      "2025-01-02 20:16:26,095 - Node Texts Length: 177, Summarized Text Length: 292\n",
      "2025-01-02 20:16:27,134 - Node Texts Length: 417, Summarized Text Length: 534\n",
      "2025-01-02 20:16:28,176 - Node Texts Length: 424, Summarized Text Length: 541\n",
      "2025-01-02 20:16:29,229 - Node Texts Length: 503, Summarized Text Length: 619\n",
      "2025-01-02 20:16:30,255 - Node Texts Length: 225, Summarized Text Length: 342\n",
      "2025-01-02 20:16:31,290 - Node Texts Length: 370, Summarized Text Length: 483\n",
      "2025-01-02 20:16:32,317 - Node Texts Length: 277, Summarized Text Length: 394\n",
      "2025-01-02 20:16:33,346 - Node Texts Length: 306, Summarized Text Length: 421\n",
      "2025-01-02 20:16:34,439 - Node Texts Length: 719, Summarized Text Length: 833\n",
      "2025-01-02 20:16:35,508 - Node Texts Length: 652, Summarized Text Length: 762\n",
      "2025-01-02 20:16:36,602 - Node Texts Length: 862, Summarized Text Length: 973\n",
      "2025-01-02 20:16:37,643 - Node Texts Length: 363, Summarized Text Length: 480\n",
      "2025-01-02 20:16:38,697 - Node Texts Length: 451, Summarized Text Length: 564\n",
      "2025-01-02 20:16:39,727 - Node Texts Length: 297, Summarized Text Length: 414\n",
      "2025-01-02 20:16:40,781 - Node Texts Length: 476, Summarized Text Length: 592\n",
      "2025-01-02 20:16:41,850 - Node Texts Length: 709, Summarized Text Length: 826\n",
      "2025-01-02 20:16:41,865 - Constructing Layer 1\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-01-02 20:16:43,553 - Summarization Length: 50\n",
      "2025-01-02 20:16:44,898 - Node Texts Length: 3066, Summarized Text Length: 3181\n",
      "2025-01-02 20:16:46,600 - Node Texts Length: 2236, Summarized Text Length: 2351\n",
      "2025-01-02 20:16:48,299 - Node Texts Length: 3363, Summarized Text Length: 3478\n",
      "2025-01-02 20:16:49,586 - Node Texts Length: 2370, Summarized Text Length: 2480\n",
      "2025-01-02 20:16:50,833 - Node Texts Length: 2060, Summarized Text Length: 2173\n",
      "2025-01-02 20:16:51,949 - Node Texts Length: 1007, Summarized Text Length: 1116\n",
      "2025-01-02 20:16:51,964 - Constructing Layer 2\n",
      "2025-01-02 20:16:51,965 - Stopping Layer construction: Cannot Create More Layers. Total Layers in tree: 2\n",
      "2025-01-02 20:16:51,965 - Successfully initialized TreeRetriever with Config \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: EMB\n",
      "            Embedding Model: <hg_rag.All_Models.SBertEmbeddingModel object at 0x7f1c14898820>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "2025-01-02 20:16:51,966 - Using collapsed_tree\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collapsed_tree\n",
      "{'node_index': 3, 'layer_number': 0, 'parent_index': 155}\n",
      "{'node_index': 28, 'layer_number': 0, 'parent_index': 144}\n",
      "{'node_index': 26, 'layer_number': 0, 'parent_index': 149}\n",
      "{'node_index': 14, 'layer_number': 0, 'parent_index': 150}\n",
      "{'node_index': 0, 'layer_number': 0, 'parent_index': 141}\n",
      "{'node_index': 2, 'layer_number': 0, 'parent_index': 155}\n",
      "{'node_index': 21, 'layer_number': 0, 'parent_index': 159}\n",
      "{'node_index': 13, 'layer_number': 0, 'parent_index': 159}\n",
      "{'node_index': 29, 'layer_number': 0, 'parent_index': 150}\n",
      "{'node_index': 9, 'layer_number': 0, 'parent_index': 141}\n",
      "{'node_index': 8, 'layer_number': 0, 'parent_index': 158}\n",
      "{'node_index': 1, 'layer_number': 0, 'parent_index': 141}\n",
      "{'node_index': 12, 'layer_number': 0, 'parent_index': 145}\n",
      "{'node_index': 4, 'layer_number': 0, 'parent_index': 156}\n",
      "{'node_index': 19, 'layer_number': 0, 'parent_index': 151}\n",
      "{'node_index': 11, 'layer_number': 0, 'parent_index': 145}\n",
      "{'node_index': 10, 'layer_number': 0, 'parent_index': 141}\n",
      "{'node_index': 31, 'layer_number': 0, 'parent_index': 150}\n",
      "{'node_index': 18, 'layer_number': 0, 'parent_index': 152}\n",
      "{'node_index': 7, 'layer_number': 0, 'parent_index': 141}\n",
      "{'node_index': 22, 'layer_number': 0, 'parent_index': 142}\n",
      "{'node_index': 6, 'layer_number': 0, 'parent_index': 157}\n",
      "{'node_index': 5, 'layer_number': 0, 'parent_index': 158}\n",
      "{'node_index': 25, 'layer_number': 0, 'parent_index': 143}\n",
      "{'node_index': 17, 'layer_number': 0, 'parent_index': 152}\n",
      "{'node_index': 27, 'layer_number': 0, 'parent_index': 144}\n",
      "{'node_index': 20, 'layer_number': 0, 'parent_index': 151}\n",
      "{'node_index': 16, 'layer_number': 0, 'parent_index': 144}\n",
      "{'node_index': 24, 'layer_number': 0, 'parent_index': 149}\n",
      "{'node_index': 15, 'layer_number': 0, 'parent_index': 152}\n",
      "{'node_index': 30, 'layer_number': 0, 'parent_index': 150}\n",
      "{'node_index': 35, 'layer_number': 0, 'parent_index': 142}\n",
      "{'node_index': 23, 'layer_number': 0, 'parent_index': 149}\n",
      "{'node_index': 32, 'layer_number': 0, 'parent_index': 152}\n",
      "{'node_index': 39, 'layer_number': 0, 'parent_index': 142}\n",
      "{'node_index': 38, 'layer_number': 0, 'parent_index': 142}\n",
      "{'node_index': 33, 'layer_number': 0, 'parent_index': 151}\n",
      "{'node_index': 47, 'layer_number': 0, 'parent_index': 154}\n",
      "{'node_index': 34, 'layer_number': 0, 'parent_index': 143}\n",
      "{'node_index': 37, 'layer_number': 0, 'parent_index': 142}\n",
      "{'node_index': 36, 'layer_number': 0, 'parent_index': 142}\n",
      "{'node_index': 50, 'layer_number': 0, 'parent_index': 160}\n",
      "{'node_index': 41, 'layer_number': 0, 'parent_index': 154}\n",
      "{'node_index': 55, 'layer_number': 0, 'parent_index': 160}\n",
      "{'node_index': 46, 'layer_number': 0, 'parent_index': 160}\n",
      "{'node_index': 54, 'layer_number': 0, 'parent_index': 160}\n",
      "{'node_index': 44, 'layer_number': 0, 'parent_index': 160}\n",
      "{'node_index': 57, 'layer_number': 0, 'parent_index': 140}\n",
      "{'node_index': 45, 'layer_number': 0, 'parent_index': 160}\n",
      "{'node_index': 53, 'layer_number': 0, 'parent_index': 160}\n",
      "{'node_index': 48, 'layer_number': 0, 'parent_index': 160}\n",
      "{'node_index': 43, 'layer_number': 0, 'parent_index': 154}\n",
      "{'node_index': 63, 'layer_number': 0, 'parent_index': 140}\n",
      "{'node_index': 42, 'layer_number': 0, 'parent_index': 154}\n",
      "{'node_index': 56, 'layer_number': 0, 'parent_index': 154}\n",
      "{'node_index': 49, 'layer_number': 0, 'parent_index': 154}\n",
      "{'node_index': 40, 'layer_number': 0, 'parent_index': 142}\n",
      "{'node_index': 51, 'layer_number': 0, 'parent_index': 160}\n",
      "{'node_index': 52, 'layer_number': 0, 'parent_index': 140}\n",
      "{'node_index': 62, 'layer_number': 0, 'parent_index': 140}\n",
      "{'node_index': 64, 'layer_number': 0, 'parent_index': 140}\n",
      "{'node_index': 66, 'layer_number': 0, 'parent_index': 154}\n",
      "{'node_index': 67, 'layer_number': 0, 'parent_index': 140}\n",
      "{'node_index': 58, 'layer_number': 0, 'parent_index': 140}\n",
      "{'node_index': 68, 'layer_number': 0, 'parent_index': 139}\n",
      "{'node_index': 61, 'layer_number': 0, 'parent_index': 140}\n",
      "{'node_index': 60, 'layer_number': 0, 'parent_index': 154}\n",
      "{'node_index': 72, 'layer_number': 0, 'parent_index': 136}\n",
      "{'node_index': 59, 'layer_number': 0, 'parent_index': 140}\n",
      "{'node_index': 69, 'layer_number': 0, 'parent_index': 139}\n",
      "{'node_index': 79, 'layer_number': 0, 'parent_index': 137}\n",
      "{'node_index': 65, 'layer_number': 0, 'parent_index': 154}\n",
      "{'node_index': 71, 'layer_number': 0, 'parent_index': 137}\n",
      "{'node_index': 76, 'layer_number': 0, 'parent_index': 139}\n",
      "{'node_index': 85, 'layer_number': 0, 'parent_index': 147}\n",
      "{'node_index': 77, 'layer_number': 0, 'parent_index': 135}\n",
      "{'node_index': 81, 'layer_number': 0, 'parent_index': 136}\n",
      "{'node_index': 80, 'layer_number': 0, 'parent_index': 136}\n",
      "{'node_index': 70, 'layer_number': 0, 'parent_index': 135}\n",
      "{'node_index': 75, 'layer_number': 0, 'parent_index': 135}\n",
      "{'node_index': 97, 'layer_number': 0, 'parent_index': 147}\n",
      "{'node_index': 78, 'layer_number': 0, 'parent_index': 137}\n",
      "{'node_index': 89, 'layer_number': 0, 'parent_index': 148}\n",
      "{'node_index': 82, 'layer_number': 0, 'parent_index': 153}\n",
      "{'node_index': 74, 'layer_number': 0, 'parent_index': 136}\n",
      "{'node_index': 84, 'layer_number': 0, 'parent_index': 159}\n",
      "{'node_index': 86, 'layer_number': 0, 'parent_index': 147}\n",
      "{'node_index': 73, 'layer_number': 0, 'parent_index': 136}\n",
      "{'node_index': 91, 'layer_number': 0, 'parent_index': 146}\n",
      "{'node_index': 93, 'layer_number': 0, 'parent_index': 146}\n",
      "{'node_index': 99, 'layer_number': 0, 'parent_index': 148}\n",
      "{'node_index': 83, 'layer_number': 0, 'parent_index': 159}\n",
      "{'node_index': 94, 'layer_number': 0, 'parent_index': 146}\n",
      "{'node_index': 110, 'layer_number': 0, 'parent_index': 155}\n",
      "{'node_index': 95, 'layer_number': 0, 'parent_index': 146}\n",
      "{'node_index': 100, 'layer_number': 0, 'parent_index': 148}\n",
      "{'node_index': 105, 'layer_number': 0, 'parent_index': 155}\n",
      "{'node_index': 90, 'layer_number': 0, 'parent_index': 148}\n",
      "{'node_index': 92, 'layer_number': 0, 'parent_index': 146}\n",
      "{'node_index': 88, 'layer_number': 0, 'parent_index': 148}\n",
      "{'node_index': 87, 'layer_number': 0, 'parent_index': 147}\n",
      "{'node_index': 101, 'layer_number': 0, 'parent_index': 159}\n",
      "{'node_index': 96, 'layer_number': 0, 'parent_index': 148}\n",
      "{'node_index': 98, 'layer_number': 0, 'parent_index': 147}\n",
      "{'node_index': 102, 'layer_number': 0, 'parent_index': 141}\n",
      "{'node_index': 111, 'layer_number': 0, 'parent_index': 155}\n",
      "{'node_index': 103, 'layer_number': 0, 'parent_index': 158}\n",
      "{'node_index': 106, 'layer_number': 0, 'parent_index': 155}\n",
      "{'node_index': 112, 'layer_number': 0, 'parent_index': 155}\n",
      "{'node_index': 104, 'layer_number': 0, 'parent_index': 155}\n",
      "{'node_index': 109, 'layer_number': 0, 'parent_index': 155}\n",
      "{'node_index': 114, 'layer_number': 0, 'parent_index': 156}\n",
      "{'node_index': 118, 'layer_number': 0, 'parent_index': 157}\n",
      "{'node_index': 134, 'layer_number': 0, 'parent_index': 153}\n",
      "{'node_index': 117, 'layer_number': 0, 'parent_index': 157}\n",
      "{'node_index': 108, 'layer_number': 0, 'parent_index': 155}\n",
      "{'node_index': 124, 'layer_number': 0, 'parent_index': 138}\n",
      "{'node_index': 107, 'layer_number': 0, 'parent_index': 157}\n",
      "{'node_index': 115, 'layer_number': 0, 'parent_index': 156}\n",
      "{'node_index': 130, 'layer_number': 0, 'parent_index': 153}\n",
      "{'node_index': 120, 'layer_number': 0, 'parent_index': 158}\n",
      "{'node_index': 116, 'layer_number': 0, 'parent_index': 141}\n",
      "{'node_index': 119, 'layer_number': 0, 'parent_index': 157}\n",
      "{'node_index': 113, 'layer_number': 0, 'parent_index': 156}\n",
      "{'node_index': 126, 'layer_number': 0, 'parent_index': 138}\n",
      "{'node_index': 125, 'layer_number': 0, 'parent_index': 138}\n",
      "{'node_index': 133, 'layer_number': 0, 'parent_index': 153}\n",
      "{'node_index': 122, 'layer_number': 0, 'parent_index': 141}\n",
      "{'node_index': 123, 'layer_number': 0, 'parent_index': 141}\n",
      "{'node_index': 127, 'layer_number': 0, 'parent_index': 153}\n",
      "{'node_index': 128, 'layer_number': 0, 'parent_index': 153}\n",
      "{'node_index': 132, 'layer_number': 0, 'parent_index': 153}\n",
      "{'node_index': 131, 'layer_number': 0, 'parent_index': 153}\n",
      "{'node_index': 121, 'layer_number': 0, 'parent_index': 159}\n",
      "{'node_index': 129, 'layer_number': 0, 'parent_index': 153}\n",
      "{'node_index': 135, 'layer_number': 1, 'parent_index': 166}\n",
      "{'node_index': 136, 'layer_number': 1, 'parent_index': 162}\n",
      "{'node_index': 137, 'layer_number': 1, 'parent_index': 166}\n",
      "{'node_index': 138, 'layer_number': 1, 'parent_index': 165}\n",
      "{'node_index': 139, 'layer_number': 1, 'parent_index': 166}\n",
      "{'node_index': 140, 'layer_number': 1, 'parent_index': 164}\n",
      "{'node_index': 141, 'layer_number': 1, 'parent_index': 163}\n",
      "{'node_index': 142, 'layer_number': 1, 'parent_index': 161}\n",
      "{'node_index': 143, 'layer_number': 1, 'parent_index': 161}\n",
      "{'node_index': 144, 'layer_number': 1, 'parent_index': 161}\n",
      "{'node_index': 145, 'layer_number': 1, 'parent_index': 165}\n",
      "{'node_index': 146, 'layer_number': 1, 'parent_index': 162}\n",
      "{'node_index': 147, 'layer_number': 1, 'parent_index': 162}\n",
      "{'node_index': 148, 'layer_number': 1, 'parent_index': 162}\n",
      "{'node_index': 149, 'layer_number': 1, 'parent_index': 161}\n",
      "{'node_index': 150, 'layer_number': 1, 'parent_index': 161}\n",
      "{'node_index': 151, 'layer_number': 1, 'parent_index': 161}\n",
      "{'node_index': 152, 'layer_number': 1, 'parent_index': 161}\n",
      "{'node_index': 153, 'layer_number': 1, 'parent_index': 165}\n",
      "{'node_index': 154, 'layer_number': 1, 'parent_index': 164}\n",
      "{'node_index': 155, 'layer_number': 1, 'parent_index': 163}\n",
      "{'node_index': 156, 'layer_number': 1, 'parent_index': 163}\n",
      "{'node_index': 157, 'layer_number': 1, 'parent_index': 163}\n",
      "{'node_index': 158, 'layer_number': 1, 'parent_index': 163}\n",
      "{'node_index': 159, 'layer_number': 1, 'parent_index': 165}\n",
      "{'node_index': 160, 'layer_number': 1, 'parent_index': 164}\n",
      "{'node_index': 161, 'layer_number': 2, 'parent_index': -1}\n",
      "{'node_index': 162, 'layer_number': 2, 'parent_index': -1}\n",
      "{'node_index': 163, 'layer_number': 2, 'parent_index': -1}\n",
      "{'node_index': 164, 'layer_number': 2, 'parent_index': -1}\n",
      "{'node_index': 165, 'layer_number': 2, 'parent_index': -1}\n",
      "{'node_index': 166, 'layer_number': 2, 'parent_index': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 20:16:57,379 - hotpotqa: 3.85\n",
      "Generating:   0%|          | 1/200 [00:57<3:11:32, 57.75s/it]2025-01-02 20:16:57,382 - Successfully initialized TreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 50\n",
      "            Summarization Model: <hg_rag.All_Models.QwenSummarizationModel object at 0x7f1c1489a590>\n",
      "            Embedding Models: {'EMB': <hg_rag.All_Models.SBertEmbeddingModel object at 0x7f1c14898820>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2025-01-02 20:16:57,382 - Successfully initialized ClusterTreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 50\n",
      "            Summarization Model: <hg_rag.All_Models.QwenSummarizationModel object at 0x7f1c1489a590>\n",
      "            Embedding Models: {'EMB': <hg_rag.All_Models.SBertEmbeddingModel object at 0x7f1c14898820>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2025-01-02 20:16:57,382 - Successfully initialized RetrievalAugmentation with Config \n",
      "        RetrievalAugmentationConfig:\n",
      "            \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 50\n",
      "            Summarization Model: <hg_rag.All_Models.QwenSummarizationModel object at 0x7f1c1489a590>\n",
      "            Embedding Models: {'EMB': <hg_rag.All_Models.SBertEmbeddingModel object at 0x7f1c14898820>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "            \n",
      "            \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: EMB\n",
      "            Embedding Model: <hg_rag.All_Models.SBertEmbeddingModel object at 0x7f1c14898820>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "            \n",
      "            QA Model: <hg_rag.All_Models.QwenQAModel object at 0x7f1c150048e0>\n",
      "            Tree Builder Type: cluster\n",
      "        \n",
      "2025-01-02 20:16:57,395 - Creating Leaf Nodes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine which case was brought to court first, we need to examine the details provided:\n",
      "\n",
      "1. **Miller v. California (1973)**: This case involved the appeal of Larry Flynt's magazine, \"Penthouse,\" which was convicted under California's obscenity laws. Miller's appeal reached the Supreme Court in 1972, where the Court issued its landmark decision in 1973. The case is noted for establishing a new standard for determining obscenity under the First Amendment.\n",
      "\n",
      "2. **Gates v. Collier (1972)**: This case involves a challenge to conditions in prison, specifically the treatment of prisoners' mail and the censorship practices of prison officials. The case was heard by the Supreme Court in 1972, resulting in a decision in 1973.\n",
      "\n",
      "Based on the information provided, **Miller v. California** was brought to the Supreme Court first, with oral arguments heard in January 1972 and a decision issued in June 1973. **Gates v. Collier** was also heard by the Supreme Court in 1972 but did not come before the Court as early as Miller v. California. Therefore, **Miller v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 20:17:02,931 - Created 193 Leaf Embeddings\n",
      "2025-01-02 20:17:02,932 - Building All Nodes\n",
      "2025-01-02 20:17:02,939 - Using Cluster TreeBuilder\n",
      "2025-01-02 20:17:02,940 - Constructing Layer 0\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-01-02 20:17:18,932 - Summarization Length: 50\n",
      "2025-01-02 20:17:19,996 - Node Texts Length: 558, Summarized Text Length: 674\n",
      "2025-01-02 20:17:21,081 - Node Texts Length: 623, Summarized Text Length: 738\n",
      "2025-01-02 20:17:22,135 - Node Texts Length: 340, Summarized Text Length: 458\n",
      "2025-01-02 20:17:23,194 - Node Texts Length: 440, Summarized Text Length: 555\n",
      "2025-01-02 20:17:24,252 - Node Texts Length: 430, Summarized Text Length: 542\n",
      "2025-01-02 20:17:25,297 - Node Texts Length: 226, Summarized Text Length: 342\n",
      "2025-01-02 20:17:26,352 - Node Texts Length: 411, Summarized Text Length: 527\n",
      "2025-01-02 20:17:27,389 - Node Texts Length: 278, Summarized Text Length: 395\n",
      "2025-01-02 20:17:28,458 - Node Texts Length: 511, Summarized Text Length: 625\n",
      "2025-01-02 20:17:29,510 - Node Texts Length: 357, Summarized Text Length: 471\n",
      "2025-01-02 20:17:30,569 - Node Texts Length: 420, Summarized Text Length: 532\n",
      "2025-01-02 20:17:31,606 - Node Texts Length: 184, Summarized Text Length: 301\n",
      "2025-01-02 20:17:32,645 - Node Texts Length: 241, Summarized Text Length: 352\n",
      "2025-01-02 20:17:33,683 - Node Texts Length: 211, Summarized Text Length: 324\n",
      "2025-01-02 20:17:34,736 - Node Texts Length: 438, Summarized Text Length: 555\n",
      "2025-01-02 20:17:35,772 - Node Texts Length: 164, Summarized Text Length: 281\n",
      "2025-01-02 20:17:36,806 - Node Texts Length: 169, Summarized Text Length: 286\n",
      "2025-01-02 20:17:37,854 - Node Texts Length: 348, Summarized Text Length: 461\n",
      "2025-01-02 20:17:38,954 - Node Texts Length: 804, Summarized Text Length: 919\n",
      "2025-01-02 20:17:39,994 - Node Texts Length: 263, Summarized Text Length: 379\n",
      "2025-01-02 20:17:41,056 - Node Texts Length: 538, Summarized Text Length: 649\n",
      "2025-01-02 20:17:42,120 - Node Texts Length: 525, Summarized Text Length: 639\n",
      "2025-01-02 20:17:43,184 - Node Texts Length: 546, Summarized Text Length: 659\n",
      "2025-01-02 20:17:44,245 - Node Texts Length: 447, Summarized Text Length: 562\n",
      "2025-01-02 20:17:45,328 - Node Texts Length: 688, Summarized Text Length: 805\n",
      "2025-01-02 20:17:46,390 - Node Texts Length: 560, Summarized Text Length: 670\n",
      "2025-01-02 20:17:47,432 - Node Texts Length: 313, Summarized Text Length: 429\n",
      "2025-01-02 20:17:48,505 - Node Texts Length: 599, Summarized Text Length: 714\n",
      "2025-01-02 20:17:49,561 - Node Texts Length: 443, Summarized Text Length: 560\n",
      "2025-01-02 20:17:50,609 - Node Texts Length: 426, Summarized Text Length: 542\n",
      "2025-01-02 20:17:51,645 - Node Texts Length: 260, Summarized Text Length: 377\n",
      "2025-01-02 20:17:52,695 - Node Texts Length: 401, Summarized Text Length: 518\n",
      "2025-01-02 20:17:53,755 - Node Texts Length: 514, Summarized Text Length: 628\n",
      "2025-01-02 20:17:54,811 - Node Texts Length: 460, Summarized Text Length: 577\n",
      "2025-01-02 20:17:55,864 - Node Texts Length: 394, Summarized Text Length: 505\n",
      "2025-01-02 20:17:56,915 - Node Texts Length: 412, Summarized Text Length: 527\n",
      "2025-01-02 20:17:57,961 - Node Texts Length: 361, Summarized Text Length: 476\n",
      "2025-01-02 20:17:59,019 - Node Texts Length: 528, Summarized Text Length: 640\n",
      "2025-01-02 20:18:00,057 - Node Texts Length: 306, Summarized Text Length: 416\n",
      "2025-01-02 20:18:00,071 - Constructing Layer 1\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-01-02 20:18:03,475 - Summarization Length: 50\n",
      "2025-01-02 20:18:04,727 - Node Texts Length: 2119, Summarized Text Length: 2232\n",
      "2025-01-02 20:18:05,824 - Node Texts Length: 713, Summarized Text Length: 826\n",
      "2025-01-02 20:18:06,942 - Node Texts Length: 1073, Summarized Text Length: 1188\n",
      "2025-01-02 20:18:07,995 - Node Texts Length: 376, Summarized Text Length: 491\n",
      "2025-01-02 20:18:09,347 - Node Texts Length: 2794, Summarized Text Length: 2909\n",
      "2025-01-02 20:18:10,739 - Node Texts Length: 3011, Summarized Text Length: 3120\n",
      "2025-01-02 20:18:12,191 - Node Texts Length: 3436, Summarized Text Length: 3549\n",
      "2025-01-02 20:18:13,404 - Node Texts Length: 1856, Summarized Text Length: 1969\n",
      "2025-01-02 20:18:14,582 - Node Texts Length: 1629, Summarized Text Length: 1744\n",
      "2025-01-02 20:18:15,855 - Node Texts Length: 2250, Summarized Text Length: 2360\n",
      "2025-01-02 20:18:17,011 - Node Texts Length: 1275, Summarized Text Length: 1385\n",
      "2025-01-02 20:18:17,030 - Constructing Layer 2\n",
      "2025-01-02 20:18:17,031 - Stopping Layer construction: Cannot Create More Layers. Total Layers in tree: 2\n",
      "2025-01-02 20:18:17,032 - Successfully initialized TreeRetriever with Config \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: EMB\n",
      "            Embedding Model: <hg_rag.All_Models.SBertEmbeddingModel object at 0x7f1c14898820>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "2025-01-02 20:18:17,032 - Using collapsed_tree\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collapsed_tree\n",
      "{'node_index': 25, 'layer_number': 0, 'parent_index': 214}\n",
      "{'node_index': 22, 'layer_number': 0, 'parent_index': 215}\n",
      "{'node_index': 3, 'layer_number': 0, 'parent_index': 226}\n",
      "{'node_index': 15, 'layer_number': 0, 'parent_index': 225}\n",
      "{'node_index': 19, 'layer_number': 0, 'parent_index': 226}\n",
      "{'node_index': 17, 'layer_number': 0, 'parent_index': 225}\n",
      "{'node_index': 24, 'layer_number': 0, 'parent_index': 218}\n",
      "{'node_index': 0, 'layer_number': 0, 'parent_index': 215}\n",
      "{'node_index': 2, 'layer_number': 0, 'parent_index': 225}\n",
      "{'node_index': 20, 'layer_number': 0, 'parent_index': 218}\n",
      "{'node_index': 1, 'layer_number': 0, 'parent_index': 225}\n",
      "{'node_index': 8, 'layer_number': 0, 'parent_index': 224}\n",
      "{'node_index': 4, 'layer_number': 0, 'parent_index': 226}\n",
      "{'node_index': 18, 'layer_number': 0, 'parent_index': 210}\n",
      "{'node_index': 5, 'layer_number': 0, 'parent_index': 224}\n",
      "{'node_index': 6, 'layer_number': 0, 'parent_index': 224}\n",
      "{'node_index': 16, 'layer_number': 0, 'parent_index': 225}\n",
      "{'node_index': 9, 'layer_number': 0, 'parent_index': 224}\n",
      "{'node_index': 14, 'layer_number': 0, 'parent_index': 225}\n",
      "{'node_index': 13, 'layer_number': 0, 'parent_index': 215}\n",
      "{'node_index': 12, 'layer_number': 0, 'parent_index': 215}\n",
      "{'node_index': 7, 'layer_number': 0, 'parent_index': 224}\n",
      "{'node_index': 10, 'layer_number': 0, 'parent_index': 226}\n",
      "{'node_index': 30, 'layer_number': 0, 'parent_index': 194}\n",
      "{'node_index': 21, 'layer_number': 0, 'parent_index': 215}\n",
      "{'node_index': 11, 'layer_number': 0, 'parent_index': 226}\n",
      "{'node_index': 32, 'layer_number': 0, 'parent_index': 197}\n",
      "{'node_index': 31, 'layer_number': 0, 'parent_index': 194}\n",
      "{'node_index': 28, 'layer_number': 0, 'parent_index': 194}\n",
      "{'node_index': 26, 'layer_number': 0, 'parent_index': 216}\n",
      "{'node_index': 23, 'layer_number': 0, 'parent_index': 213}\n",
      "{'node_index': 36, 'layer_number': 0, 'parent_index': 197}\n",
      "{'node_index': 27, 'layer_number': 0, 'parent_index': 194}\n",
      "{'node_index': 29, 'layer_number': 0, 'parent_index': 198}\n",
      "{'node_index': 33, 'layer_number': 0, 'parent_index': 199}\n",
      "{'node_index': 46, 'layer_number': 0, 'parent_index': 193}\n",
      "{'node_index': 49, 'layer_number': 0, 'parent_index': 212}\n",
      "{'node_index': 37, 'layer_number': 0, 'parent_index': 196}\n",
      "{'node_index': 39, 'layer_number': 0, 'parent_index': 199}\n",
      "{'node_index': 34, 'layer_number': 0, 'parent_index': 199}\n",
      "{'node_index': 40, 'layer_number': 0, 'parent_index': 199}\n",
      "{'node_index': 56, 'layer_number': 0, 'parent_index': 213}\n",
      "{'node_index': 41, 'layer_number': 0, 'parent_index': 197}\n",
      "{'node_index': 58, 'layer_number': 0, 'parent_index': 213}\n",
      "{'node_index': 51, 'layer_number': 0, 'parent_index': 220}\n",
      "{'node_index': 55, 'layer_number': 0, 'parent_index': 211}\n",
      "{'node_index': 42, 'layer_number': 0, 'parent_index': 197}\n",
      "{'node_index': 54, 'layer_number': 0, 'parent_index': 220}\n",
      "{'node_index': 35, 'layer_number': 0, 'parent_index': 194}\n",
      "{'node_index': 38, 'layer_number': 0, 'parent_index': 199}\n",
      "{'node_index': 43, 'layer_number': 0, 'parent_index': 217}\n",
      "{'node_index': 45, 'layer_number': 0, 'parent_index': 193}\n",
      "{'node_index': 59, 'layer_number': 0, 'parent_index': 217}\n",
      "{'node_index': 50, 'layer_number': 0, 'parent_index': 220}\n",
      "{'node_index': 47, 'layer_number': 0, 'parent_index': 193}\n",
      "{'node_index': 44, 'layer_number': 0, 'parent_index': 217}\n",
      "{'node_index': 52, 'layer_number': 0, 'parent_index': 215}\n",
      "{'node_index': 71, 'layer_number': 0, 'parent_index': 219}\n",
      "{'node_index': 48, 'layer_number': 0, 'parent_index': 220}\n",
      "{'node_index': 63, 'layer_number': 0, 'parent_index': 219}\n",
      "{'node_index': 57, 'layer_number': 0, 'parent_index': 211}\n",
      "{'node_index': 74, 'layer_number': 0, 'parent_index': 220}\n",
      "{'node_index': 65, 'layer_number': 0, 'parent_index': 217}\n",
      "{'node_index': 67, 'layer_number': 0, 'parent_index': 193}\n",
      "{'node_index': 53, 'layer_number': 0, 'parent_index': 213}\n",
      "{'node_index': 75, 'layer_number': 0, 'parent_index': 220}\n",
      "{'node_index': 61, 'layer_number': 0, 'parent_index': 217}\n",
      "{'node_index': 64, 'layer_number': 0, 'parent_index': 217}\n",
      "{'node_index': 73, 'layer_number': 0, 'parent_index': 211}\n",
      "{'node_index': 77, 'layer_number': 0, 'parent_index': 214}\n",
      "{'node_index': 79, 'layer_number': 0, 'parent_index': 211}\n",
      "{'node_index': 62, 'layer_number': 0, 'parent_index': 211}\n",
      "{'node_index': 76, 'layer_number': 0, 'parent_index': 219}\n",
      "{'node_index': 60, 'layer_number': 0, 'parent_index': 217}\n",
      "{'node_index': 80, 'layer_number': 0, 'parent_index': 214}\n",
      "{'node_index': 81, 'layer_number': 0, 'parent_index': 227}\n",
      "{'node_index': 78, 'layer_number': 0, 'parent_index': 214}\n",
      "{'node_index': 82, 'layer_number': 0, 'parent_index': 214}\n",
      "{'node_index': 68, 'layer_number': 0, 'parent_index': 193}\n",
      "{'node_index': 72, 'layer_number': 0, 'parent_index': 211}\n",
      "{'node_index': 87, 'layer_number': 0, 'parent_index': 214}\n",
      "{'node_index': 88, 'layer_number': 0, 'parent_index': 216}\n",
      "{'node_index': 66, 'layer_number': 0, 'parent_index': 217}\n",
      "{'node_index': 83, 'layer_number': 0, 'parent_index': 218}\n",
      "{'node_index': 69, 'layer_number': 0, 'parent_index': 212}\n",
      "{'node_index': 70, 'layer_number': 0, 'parent_index': 213}\n",
      "{'node_index': 86, 'layer_number': 0, 'parent_index': 218}\n",
      "{'node_index': 84, 'layer_number': 0, 'parent_index': 218}\n",
      "{'node_index': 89, 'layer_number': 0, 'parent_index': 211}\n",
      "{'node_index': 93, 'layer_number': 0, 'parent_index': 216}\n",
      "{'node_index': 106, 'layer_number': 0, 'parent_index': 194}\n",
      "{'node_index': 103, 'layer_number': 0, 'parent_index': 218}\n",
      "{'node_index': 98, 'layer_number': 0, 'parent_index': 218}\n",
      "{'node_index': 96, 'layer_number': 0, 'parent_index': 215}\n",
      "{'node_index': 101, 'layer_number': 0, 'parent_index': 196}\n",
      "{'node_index': 97, 'layer_number': 0, 'parent_index': 218}\n",
      "{'node_index': 90, 'layer_number': 0, 'parent_index': 220}\n",
      "{'node_index': 92, 'layer_number': 0, 'parent_index': 216}\n",
      "{'node_index': 94, 'layer_number': 0, 'parent_index': 211}\n",
      "{'node_index': 85, 'layer_number': 0, 'parent_index': 211}\n",
      "{'node_index': 99, 'layer_number': 0, 'parent_index': 216}\n",
      "{'node_index': 104, 'layer_number': 0, 'parent_index': 196}\n",
      "{'node_index': 112, 'layer_number': 0, 'parent_index': 195}\n",
      "{'node_index': 107, 'layer_number': 0, 'parent_index': 194}\n",
      "{'node_index': 91, 'layer_number': 0, 'parent_index': 219}\n",
      "{'node_index': 95, 'layer_number': 0, 'parent_index': 211}\n",
      "{'node_index': 113, 'layer_number': 0, 'parent_index': 198}\n",
      "{'node_index': 115, 'layer_number': 0, 'parent_index': 198}\n",
      "{'node_index': 111, 'layer_number': 0, 'parent_index': 195}\n",
      "{'node_index': 122, 'layer_number': 0, 'parent_index': 229}\n",
      "{'node_index': 117, 'layer_number': 0, 'parent_index': 200}\n",
      "{'node_index': 100, 'layer_number': 0, 'parent_index': 200}\n",
      "{'node_index': 108, 'layer_number': 0, 'parent_index': 195}\n",
      "{'node_index': 114, 'layer_number': 0, 'parent_index': 228}\n",
      "{'node_index': 124, 'layer_number': 0, 'parent_index': 229}\n",
      "{'node_index': 125, 'layer_number': 0, 'parent_index': 231}\n",
      "{'node_index': 102, 'layer_number': 0, 'parent_index': 212}\n",
      "{'node_index': 105, 'layer_number': 0, 'parent_index': 194}\n",
      "{'node_index': 109, 'layer_number': 0, 'parent_index': 197}\n",
      "{'node_index': 120, 'layer_number': 0, 'parent_index': 196}\n",
      "{'node_index': 116, 'layer_number': 0, 'parent_index': 213}\n",
      "{'node_index': 127, 'layer_number': 0, 'parent_index': 230}\n",
      "{'node_index': 126, 'layer_number': 0, 'parent_index': 210}\n",
      "{'node_index': 110, 'layer_number': 0, 'parent_index': 195}\n",
      "{'node_index': 121, 'layer_number': 0, 'parent_index': 229}\n",
      "{'node_index': 123, 'layer_number': 0, 'parent_index': 229}\n",
      "{'node_index': 118, 'layer_number': 0, 'parent_index': 200}\n",
      "{'node_index': 119, 'layer_number': 0, 'parent_index': 196}\n",
      "{'node_index': 150, 'layer_number': 0, 'parent_index': 222}\n",
      "{'node_index': 140, 'layer_number': 0, 'parent_index': 210}\n",
      "{'node_index': 130, 'layer_number': 0, 'parent_index': 209}\n",
      "{'node_index': 132, 'layer_number': 0, 'parent_index': 207}\n",
      "{'node_index': 129, 'layer_number': 0, 'parent_index': 207}\n",
      "{'node_index': 138, 'layer_number': 0, 'parent_index': 230}\n",
      "{'node_index': 135, 'layer_number': 0, 'parent_index': 207}\n",
      "{'node_index': 143, 'layer_number': 0, 'parent_index': 227}\n",
      "{'node_index': 144, 'layer_number': 0, 'parent_index': 227}\n",
      "{'node_index': 128, 'layer_number': 0, 'parent_index': 208}\n",
      "{'node_index': 133, 'layer_number': 0, 'parent_index': 207}\n",
      "{'node_index': 141, 'layer_number': 0, 'parent_index': 230}\n",
      "{'node_index': 136, 'layer_number': 0, 'parent_index': 208}\n",
      "{'node_index': 148, 'layer_number': 0, 'parent_index': 222}\n",
      "{'node_index': 137, 'layer_number': 0, 'parent_index': 210}\n",
      "{'node_index': 142, 'layer_number': 0, 'parent_index': 227}\n",
      "{'node_index': 134, 'layer_number': 0, 'parent_index': 207}\n",
      "{'node_index': 131, 'layer_number': 0, 'parent_index': 209}\n",
      "{'node_index': 139, 'layer_number': 0, 'parent_index': 230}\n",
      "{'node_index': 147, 'layer_number': 0, 'parent_index': 227}\n",
      "{'node_index': 145, 'layer_number': 0, 'parent_index': 230}\n",
      "{'node_index': 156, 'layer_number': 0, 'parent_index': 223}\n",
      "{'node_index': 151, 'layer_number': 0, 'parent_index': 222}\n",
      "{'node_index': 146, 'layer_number': 0, 'parent_index': 230}\n",
      "{'node_index': 149, 'layer_number': 0, 'parent_index': 223}\n",
      "{'node_index': 155, 'layer_number': 0, 'parent_index': 221}\n",
      "{'node_index': 159, 'layer_number': 0, 'parent_index': 206}\n",
      "{'node_index': 152, 'layer_number': 0, 'parent_index': 221}\n",
      "{'node_index': 153, 'layer_number': 0, 'parent_index': 221}\n",
      "{'node_index': 161, 'layer_number': 0, 'parent_index': 202}\n",
      "{'node_index': 160, 'layer_number': 0, 'parent_index': 223}\n",
      "{'node_index': 157, 'layer_number': 0, 'parent_index': 203}\n",
      "{'node_index': 169, 'layer_number': 0, 'parent_index': 203}\n",
      "{'node_index': 163, 'layer_number': 0, 'parent_index': 204}\n",
      "{'node_index': 173, 'layer_number': 0, 'parent_index': 205}\n",
      "{'node_index': 166, 'layer_number': 0, 'parent_index': 205}\n",
      "{'node_index': 175, 'layer_number': 0, 'parent_index': 201}\n",
      "{'node_index': 170, 'layer_number': 0, 'parent_index': 201}\n",
      "{'node_index': 158, 'layer_number': 0, 'parent_index': 206}\n",
      "{'node_index': 167, 'layer_number': 0, 'parent_index': 202}\n",
      "{'node_index': 164, 'layer_number': 0, 'parent_index': 204}\n",
      "{'node_index': 154, 'layer_number': 0, 'parent_index': 221}\n",
      "{'node_index': 168, 'layer_number': 0, 'parent_index': 203}\n",
      "{'node_index': 178, 'layer_number': 0, 'parent_index': 206}\n",
      "{'node_index': 187, 'layer_number': 0, 'parent_index': 231}\n",
      "{'node_index': 174, 'layer_number': 0, 'parent_index': 201}\n",
      "{'node_index': 171, 'layer_number': 0, 'parent_index': 201}\n",
      "{'node_index': 190, 'layer_number': 0, 'parent_index': 228}\n",
      "{'node_index': 182, 'layer_number': 0, 'parent_index': 203}\n",
      "{'node_index': 165, 'layer_number': 0, 'parent_index': 204}\n",
      "{'node_index': 162, 'layer_number': 0, 'parent_index': 202}\n",
      "{'node_index': 185, 'layer_number': 0, 'parent_index': 221}\n",
      "{'node_index': 176, 'layer_number': 0, 'parent_index': 201}\n",
      "{'node_index': 184, 'layer_number': 0, 'parent_index': 222}\n",
      "{'node_index': 181, 'layer_number': 0, 'parent_index': 202}\n",
      "{'node_index': 188, 'layer_number': 0, 'parent_index': 231}\n",
      "{'node_index': 172, 'layer_number': 0, 'parent_index': 201}\n",
      "{'node_index': 179, 'layer_number': 0, 'parent_index': 223}\n",
      "{'node_index': 186, 'layer_number': 0, 'parent_index': 231}\n",
      "{'node_index': 191, 'layer_number': 0, 'parent_index': 228}\n",
      "{'node_index': 183, 'layer_number': 0, 'parent_index': 222}\n",
      "{'node_index': 180, 'layer_number': 0, 'parent_index': 205}\n",
      "{'node_index': 177, 'layer_number': 0, 'parent_index': 203}\n",
      "{'node_index': 192, 'layer_number': 0, 'parent_index': 228}\n",
      "{'node_index': 189, 'layer_number': 0, 'parent_index': 228}\n",
      "{'node_index': 193, 'layer_number': 1, 'parent_index': 238}\n",
      "{'node_index': 194, 'layer_number': 1, 'parent_index': 241}\n",
      "{'node_index': 195, 'layer_number': 1, 'parent_index': 241}\n",
      "{'node_index': 196, 'layer_number': 1, 'parent_index': 238}\n",
      "{'node_index': 197, 'layer_number': 1, 'parent_index': 238}\n",
      "{'node_index': 198, 'layer_number': 1, 'parent_index': 238}\n",
      "{'node_index': 199, 'layer_number': 1, 'parent_index': 238}\n",
      "{'node_index': 200, 'layer_number': 1, 'parent_index': 241}\n",
      "{'node_index': 201, 'layer_number': 1, 'parent_index': 242}\n",
      "{'node_index': 202, 'layer_number': 1, 'parent_index': 236}\n",
      "{'node_index': 203, 'layer_number': 1, 'parent_index': 236}\n",
      "{'node_index': 204, 'layer_number': 1, 'parent_index': 242}\n",
      "{'node_index': 205, 'layer_number': 1, 'parent_index': 242}\n",
      "{'node_index': 206, 'layer_number': 1, 'parent_index': 236}\n",
      "{'node_index': 207, 'layer_number': 1, 'parent_index': 240}\n",
      "{'node_index': 208, 'layer_number': 1, 'parent_index': 240}\n",
      "{'node_index': 209, 'layer_number': 1, 'parent_index': 240}\n",
      "{'node_index': 210, 'layer_number': 1, 'parent_index': 237}\n",
      "{'node_index': 211, 'layer_number': 1, 'parent_index': 232}\n",
      "{'node_index': 212, 'layer_number': 1, 'parent_index': 235}\n",
      "{'node_index': 213, 'layer_number': 1, 'parent_index': 234}\n",
      "{'node_index': 214, 'layer_number': 1, 'parent_index': 232}\n",
      "{'node_index': 215, 'layer_number': 1, 'parent_index': 239}\n",
      "{'node_index': 216, 'layer_number': 1, 'parent_index': 232}\n",
      "{'node_index': 217, 'layer_number': 1, 'parent_index': 238}\n",
      "{'node_index': 218, 'layer_number': 1, 'parent_index': 241}\n",
      "{'node_index': 219, 'layer_number': 1, 'parent_index': 234}\n",
      "{'node_index': 220, 'layer_number': 1, 'parent_index': 233}\n",
      "{'node_index': 221, 'layer_number': 1, 'parent_index': 236}\n",
      "{'node_index': 222, 'layer_number': 1, 'parent_index': 236}\n",
      "{'node_index': 223, 'layer_number': 1, 'parent_index': 236}\n",
      "{'node_index': 224, 'layer_number': 1, 'parent_index': 240}\n",
      "{'node_index': 225, 'layer_number': 1, 'parent_index': 239}\n",
      "{'node_index': 226, 'layer_number': 1, 'parent_index': 239}\n",
      "{'node_index': 227, 'layer_number': 1, 'parent_index': 237}\n",
      "{'node_index': 228, 'layer_number': 1, 'parent_index': 237}\n",
      "{'node_index': 229, 'layer_number': 1, 'parent_index': 237}\n",
      "{'node_index': 230, 'layer_number': 1, 'parent_index': 237}\n",
      "{'node_index': 231, 'layer_number': 1, 'parent_index': 237}\n",
      "{'node_index': 232, 'layer_number': 2, 'parent_index': -1}\n",
      "{'node_index': 233, 'layer_number': 2, 'parent_index': -1}\n",
      "{'node_index': 234, 'layer_number': 2, 'parent_index': -1}\n",
      "{'node_index': 235, 'layer_number': 2, 'parent_index': -1}\n",
      "{'node_index': 236, 'layer_number': 2, 'parent_index': -1}\n",
      "{'node_index': 237, 'layer_number': 2, 'parent_index': -1}\n",
      "{'node_index': 238, 'layer_number': 2, 'parent_index': -1}\n",
      "{'node_index': 239, 'layer_number': 2, 'parent_index': -1}\n",
      "{'node_index': 240, 'layer_number': 2, 'parent_index': -1}\n",
      "{'node_index': 241, 'layer_number': 2, 'parent_index': -1}\n",
      "{'node_index': 242, 'layer_number': 2, 'parent_index': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 20:18:19,698 - hotpotqa: 1.92\n",
      "Generating:   1%|          | 2/200 [02:20<3:58:16, 72.20s/it]2025-01-02 20:18:19,702 - Successfully initialized TreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 50\n",
      "            Summarization Model: <hg_rag.All_Models.QwenSummarizationModel object at 0x7f1c1489a590>\n",
      "            Embedding Models: {'EMB': <hg_rag.All_Models.SBertEmbeddingModel object at 0x7f1c14898820>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2025-01-02 20:18:19,703 - Successfully initialized ClusterTreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 50\n",
      "            Summarization Model: <hg_rag.All_Models.QwenSummarizationModel object at 0x7f1c1489a590>\n",
      "            Embedding Models: {'EMB': <hg_rag.All_Models.SBertEmbeddingModel object at 0x7f1c14898820>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2025-01-02 20:18:19,704 - Successfully initialized RetrievalAugmentation with Config \n",
      "        RetrievalAugmentationConfig:\n",
      "            \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 50\n",
      "            Summarization Model: <hg_rag.All_Models.QwenSummarizationModel object at 0x7f1c1489a590>\n",
      "            Embedding Models: {'EMB': <hg_rag.All_Models.SBertEmbeddingModel object at 0x7f1c14898820>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "            \n",
      "            \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: EMB\n",
      "            Embedding Model: <hg_rag.All_Models.SBertEmbeddingModel object at 0x7f1c14898820>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "            \n",
      "            QA Model: <hg_rag.All_Models.QwenQAModel object at 0x7f1c150048e0>\n",
      "            Tree Builder Type: cluster\n",
      "        \n",
      "2025-01-02 20:18:19,719 - Creating Leaf Nodes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actor who played Phileas Fogg in the 1956 film \"Around the World in 80 Days\" was Cantinflas. However, the information you're seeking pertains to the 1939 film adaptation of the same story. In the 1939 film, the actor who played Phileas Fogg was Michael Redgrave.\n",
      "\n",
      "Michael Redgrave starred alongside Gary Cooper in \"Around the World in 80 Days,\" which was based on the novel by Jules Verne. This film was produced by Goldwyn Productions and released in 1939.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 20:18:24,923 - Created 191 Leaf Embeddings\n",
      "2025-01-02 20:18:24,924 - Building All Nodes\n",
      "2025-01-02 20:18:24,931 - Using Cluster TreeBuilder\n",
      "2025-01-02 20:18:24,931 - Constructing Layer 0\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-01-02 20:18:39,357 - Summarization Length: 50\n",
      "2025-01-02 20:18:40,408 - Node Texts Length: 388, Summarized Text Length: 504\n",
      "2025-01-02 20:18:41,473 - Node Texts Length: 377, Summarized Text Length: 491\n",
      "2025-01-02 20:18:42,553 - Node Texts Length: 460, Summarized Text Length: 574\n",
      "2025-01-02 20:18:43,635 - Node Texts Length: 639, Summarized Text Length: 754\n",
      "2025-01-02 20:18:44,712 - Node Texts Length: 558, Summarized Text Length: 673\n",
      "2025-01-02 20:18:45,777 - Node Texts Length: 464, Summarized Text Length: 580\n",
      "2025-01-02 20:18:46,854 - Node Texts Length: 569, Summarized Text Length: 686\n",
      "2025-01-02 20:18:47,945 - Node Texts Length: 658, Summarized Text Length: 774\n",
      "2025-01-02 20:18:49,022 - Node Texts Length: 644, Summarized Text Length: 760\n",
      "2025-01-02 20:18:50,081 - Node Texts Length: 416, Summarized Text Length: 530\n",
      "2025-01-02 20:18:51,126 - Node Texts Length: 248, Summarized Text Length: 361\n",
      "2025-01-02 20:18:52,183 - Node Texts Length: 342, Summarized Text Length: 456\n",
      "2025-01-02 20:18:53,239 - Node Texts Length: 378, Summarized Text Length: 494\n",
      "2025-01-02 20:18:54,292 - Node Texts Length: 342, Summarized Text Length: 456\n",
      "2025-01-02 20:18:55,347 - Node Texts Length: 338, Summarized Text Length: 449\n",
      "2025-01-02 20:18:56,404 - Node Texts Length: 457, Summarized Text Length: 573\n",
      "2025-01-02 20:18:57,451 - Node Texts Length: 244, Summarized Text Length: 354\n",
      "2025-01-02 20:18:58,490 - Node Texts Length: 265, Summarized Text Length: 379\n",
      "2025-01-02 20:18:59,534 - Node Texts Length: 229, Summarized Text Length: 339\n",
      "2025-01-02 20:19:00,581 - Node Texts Length: 248, Summarized Text Length: 361\n",
      "2025-01-02 20:19:01,662 - Node Texts Length: 620, Summarized Text Length: 733\n",
      "2025-01-02 20:19:02,729 - Node Texts Length: 513, Summarized Text Length: 628\n",
      "2025-01-02 20:19:03,805 - Node Texts Length: 679, Summarized Text Length: 794\n",
      "2025-01-02 20:19:04,884 - Node Texts Length: 627, Summarized Text Length: 741\n",
      "2025-01-02 20:19:05,930 - Node Texts Length: 283, Summarized Text Length: 398\n",
      "2025-01-02 20:19:07,437 - Node Texts Length: 422, Summarized Text Length: 538\n",
      "2025-01-02 20:19:08,875 - Node Texts Length: 283, Summarized Text Length: 396\n",
      "2025-01-02 20:19:09,934 - Node Texts Length: 322, Summarized Text Length: 437\n",
      "2025-01-02 20:19:11,003 - Node Texts Length: 359, Summarized Text Length: 473\n",
      "2025-01-02 20:19:12,078 - Node Texts Length: 497, Summarized Text Length: 612\n",
      "2025-01-02 20:19:13,152 - Node Texts Length: 371, Summarized Text Length: 487\n",
      "2025-01-02 20:19:14,241 - Node Texts Length: 583, Summarized Text Length: 693\n",
      "2025-01-02 20:19:15,339 - Node Texts Length: 723, Summarized Text Length: 837\n",
      "2025-01-02 20:19:16,429 - Node Texts Length: 663, Summarized Text Length: 774\n",
      "2025-01-02 20:19:17,478 - Node Texts Length: 77, Summarized Text Length: 190\n",
      "2025-01-02 20:19:18,552 - Node Texts Length: 433, Summarized Text Length: 546\n",
      "2025-01-02 20:19:19,621 - Node Texts Length: 330, Summarized Text Length: 443\n",
      "2025-01-02 20:19:19,633 - Constructing Layer 1\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-01-02 20:19:25,328 - Summarization Length: 50\n",
      "2025-01-02 20:19:26,474 - Node Texts Length: 1425, Summarized Text Length: 1537\n",
      "2025-01-02 20:19:27,677 - Node Texts Length: 1731, Summarized Text Length: 1844\n",
      "2025-01-02 20:19:28,842 - Node Texts Length: 1429, Summarized Text Length: 1543\n",
      "2025-01-02 20:19:29,997 - Node Texts Length: 1238, Summarized Text Length: 1346\n",
      "2025-01-02 20:19:31,067 - Node Texts Length: 577, Summarized Text Length: 692\n",
      "2025-01-02 20:19:32,227 - Node Texts Length: 1273, Summarized Text Length: 1384\n",
      "2025-01-02 20:19:33,335 - Node Texts Length: 951, Summarized Text Length: 1066\n",
      "2025-01-02 20:19:34,414 - Node Texts Length: 686, Summarized Text Length: 797\n",
      "2025-01-02 20:19:35,486 - Node Texts Length: 430, Summarized Text Length: 543\n",
      "2025-01-02 20:19:36,650 - Node Texts Length: 1435, Summarized Text Length: 1548\n",
      "2025-01-02 20:19:37,944 - Node Texts Length: 2337, Summarized Text Length: 2448\n",
      "2025-01-02 20:19:39,340 - Node Texts Length: 3081, Summarized Text Length: 3196\n",
      "2025-01-02 20:19:40,602 - Node Texts Length: 2144, Summarized Text Length: 2257\n",
      "2025-01-02 20:19:41,758 - Node Texts Length: 1412, Summarized Text Length: 1521\n",
      "2025-01-02 20:19:41,774 - Constructing Layer 2\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/rt/data/miniconda3/envs/RAG/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "Generating:   1%|          | 2/200 [03:43<6:09:35, 112.00s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_neighbors must be greater than 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 42\u001b[0m\n\u001b[1;32m     34\u001b[0m RAC \u001b[38;5;241m=\u001b[39m RetrievalAugmentationConfig(\n\u001b[1;32m     35\u001b[0m     summarization_model\u001b[38;5;241m=\u001b[39msum_model[\u001b[38;5;241m0\u001b[39m], \n\u001b[1;32m     36\u001b[0m     qa_model\u001b[38;5;241m=\u001b[39mqa_model[\u001b[38;5;241m0\u001b[39m], \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     tb_summarization_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     41\u001b[0m RA \u001b[38;5;241m=\u001b[39m RetrievalAugmentation(config\u001b[38;5;241m=\u001b[39mRAC)\n\u001b[0;32m---> 42\u001b[0m \u001b[43mRA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# persist_path='./db3'\u001b[39;00m\n\u001b[1;32m     43\u001b[0m output \u001b[38;5;241m=\u001b[39m RA\u001b[38;5;241m.\u001b[39manswer_question(question\u001b[38;5;241m=\u001b[39mx[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# output = gen_model.generate(prompts=prompt, max_new_tokens=task_max_new_token, do_sample=True)\u001b[39;00m\n",
      "File \u001b[0;32m/nvme1/data_rt/hierarchy_graphrag/hg_rag/RetrievalAugmentation.py:215\u001b[0m, in \u001b[0;36mRetrievalAugmentation.add_documents\u001b[0;34m(self, docs, persist_path)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;66;03m# self.add_to_existing(docs)\u001b[39;00m\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersist_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretriever \u001b[38;5;241m=\u001b[39m TreeRetriever(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_retriever_config, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree, persist_path\u001b[38;5;241m=\u001b[39mpersist_path)\n",
      "File \u001b[0;32m/nvme1/data_rt/hierarchy_graphrag/hg_rag/cluster_tree_builder.py:293\u001b[0m, in \u001b[0;36mTreeBuilder.build_from_text\u001b[0;34m(self, text, use_multithreading, persist_path)\u001b[0m\n\u001b[1;32m    289\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuilding All Nodes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    291\u001b[0m all_nodes \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(leaf_nodes)\n\u001b[0;32m--> 293\u001b[0m root_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_to_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m tree \u001b[38;5;241m=\u001b[39m Tree(all_nodes, root_nodes, leaf_nodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, layer_to_nodes)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m persist_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/nvme1/data_rt/hierarchy_graphrag/hg_rag/cluster_tree_builder.py:421\u001b[0m, in \u001b[0;36mClusterTreeBuilder.construct_tree\u001b[0;34m(self, current_level_nodes, all_tree_nodes, layer_to_nodes, use_multithreading)\u001b[0m\n\u001b[1;32m    416\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopping Layer construction: Cannot Create More Layers. Total Layers in tree: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m     )\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclustering_algorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_clustering\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_list_current_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcluster_embedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreduction_dimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction_dimension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclustering_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m lock \u001b[38;5;241m=\u001b[39m Lock()\n\u001b[1;32m    430\u001b[0m summarization_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msummarization_length\n",
      "File \u001b[0;32m/nvme1/data_rt/hierarchy_graphrag/hg_rag/cluster_utils.py:178\u001b[0m, in \u001b[0;36mRAPTOR_Clustering.perform_clustering\u001b[0;34m(nodes, embedding_model_name, max_length_in_cluster, tokenizer, reduction_dimension, threshold, verbose)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    174\u001b[0m         logging\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    175\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreclustering cluster with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(cluster_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m nodes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m         )\n\u001b[1;32m    177\u001b[0m     node_clusters\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m--> 178\u001b[0m         \u001b[43mRAPTOR_Clustering\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_clustering\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcluster_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length_in_cluster\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m     )\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     node_clusters\u001b[38;5;241m.\u001b[39mappend(cluster_nodes)\n",
      "File \u001b[0;32m/nvme1/data_rt/hierarchy_graphrag/hg_rag/cluster_utils.py:146\u001b[0m, in \u001b[0;36mRAPTOR_Clustering.perform_clustering\u001b[0;34m(nodes, embedding_model_name, max_length_in_cluster, tokenizer, reduction_dimension, threshold, verbose)\u001b[0m\n\u001b[1;32m    143\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([node\u001b[38;5;241m.\u001b[39membeddings[embedding_model_name] \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes])\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Perform the clustering\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m clusters \u001b[38;5;241m=\u001b[39m \u001b[43mperform_clustering\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduction_dimension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# Initialize an empty list to store the clusters of nodes\u001b[39;00m\n\u001b[1;32m    151\u001b[0m node_clusters \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/nvme1/data_rt/hierarchy_graphrag/hg_rag/cluster_utils.py:72\u001b[0m, in \u001b[0;36mperform_clustering\u001b[0;34m(embeddings, dim, threshold, verbose)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_clustering\u001b[39m(\n\u001b[1;32m     70\u001b[0m     embeddings: np\u001b[38;5;241m.\u001b[39mndarray, dim: \u001b[38;5;28mint\u001b[39m, threshold: \u001b[38;5;28mfloat\u001b[39m, verbose: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     71\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[0;32m---> 72\u001b[0m     reduced_embeddings_global \u001b[38;5;241m=\u001b[39m \u001b[43mglobal_cluster_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     global_clusters, n_global_clusters \u001b[38;5;241m=\u001b[39m GMM_cluster(\n\u001b[1;32m     74\u001b[0m         reduced_embeddings_global, threshold\n\u001b[1;32m     75\u001b[0m     )\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m/nvme1/data_rt/hierarchy_graphrag/hg_rag/cluster_utils.py:33\u001b[0m, in \u001b[0;36mglobal_cluster_embeddings\u001b[0;34m(embeddings, dim, n_neighbors, metric)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     n_neighbors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((\u001b[38;5;28mlen\u001b[39m(embeddings) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     31\u001b[0m reduced_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mumap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUMAP\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\n\u001b[0;32m---> 33\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reduced_embeddings\n",
      "File \u001b[0;32m~/data/miniconda3/envs/RAG/lib/python3.10/site-packages/umap/umap_.py:2887\u001b[0m, in \u001b[0;36mUMAP.fit_transform\u001b[0;34m(self, X, y, force_all_finite)\u001b[0m\n\u001b[1;32m   2851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   2852\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed\u001b[39;00m\n\u001b[1;32m   2853\u001b[0m \u001b[38;5;124;03m    output.\u001b[39;00m\n\u001b[1;32m   2854\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2885\u001b[0m \u001b[38;5;124;03m        Local radii of data points in the embedding (log-transformed).\u001b[39;00m\n\u001b[1;32m   2886\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2887\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2888\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2889\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dens:\n",
      "File \u001b[0;32m~/data/miniconda3/envs/RAG/lib/python3.10/site-packages/umap/umap_.py:2379\u001b[0m, in \u001b[0;36mUMAP.fit\u001b[0;34m(self, X, y, force_all_finite)\u001b[0m\n\u001b[1;32m   2376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2377\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknn_search_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecomputed_knn[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m-> 2379\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m   2382\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n",
      "File \u001b[0;32m~/data/miniconda3/envs/RAG/lib/python3.10/site-packages/umap/umap_.py:1777\u001b[0m, in \u001b[0;36mUMAP._validate_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate must be positive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1776\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_neighbors \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1777\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neighbors must be greater than 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_n_neighbors \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_n_neighbors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_n_neighbors must be greater than 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: n_neighbors must be greater than 1"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "result_dir = ''\n",
    "result_dir = os.path.join(output_dir, result_dir)\n",
    "\n",
    "for i, dataset_name in enumerate(dataset_names):\n",
    "    logger.info(f\"Evaluating {dataset_name} ({i + 1} / {len(dataset_names)})...\")\n",
    "\n",
    "    result_path = os.path.join(result_dir, f\"{dataset_name}.json\")\n",
    "    \n",
    "    dataset = datasets.Dataset.from_pandas(groupby_dataset.get_group(dataset_name), preserve_index=False)\n",
    "\n",
    "    data_collator = DefaultDataCollator(padding_side=\"left\")\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=1, \n",
    "        collate_fn=data_collator,\n",
    "        # only pin memory when no gpu\n",
    "    )\n",
    "\n",
    "    indices = []\n",
    "    preds = []\n",
    "    memory_results = []\n",
    "    _prompt = DATASET2PROMPT[dataset_name]\n",
    "    task_max_new_token=DATASET2MAXNEWTOKENS[dataset_name]\n",
    "    \n",
    "    for i, x in enumerate(tqdm(dataloader, desc=\"Generating\")):\n",
    "        x.pop(\"dataset\")\n",
    "        index = x.pop(\"index\")[0]\n",
    "\n",
    "        # # generate output\n",
    "        # prompt = _prompt.format(context=x[\"context\"][0], input=x[\"question\"][0])\n",
    "\n",
    "        from hg_rag import RetrievalAugmentation, RetrievalAugmentationConfig\n",
    "        RAC = RetrievalAugmentationConfig(\n",
    "            summarization_model=sum_model[0], \n",
    "            qa_model=qa_model[0], \n",
    "            # embedding_model=BAAIEmbeddingModel(model_path='/home/rt/data/model/BAAI/bge-m3')\n",
    "            embedding_model=emb_model,\n",
    "            tb_summarization_length=50,\n",
    "        )\n",
    "        RA = RetrievalAugmentation(config=RAC)\n",
    "        RA.add_documents(x[\"context\"][0]) # persist_path='./db3'\n",
    "        output = RA.answer_question(question=x[\"question\"][0], prompt_template=_prompt, gen_max_tokens=task_max_new_token)\n",
    "        # output = gen_model.generate(prompts=prompt, max_new_tokens=task_max_new_token, do_sample=True)\n",
    "\n",
    "        print(output)\n",
    "        output = [output]\n",
    "\n",
    "        index = index.tolist()\n",
    "        preds.extend(output)\n",
    "        if isinstance(index, list):\n",
    "            indices.extend(index)\n",
    "        else:\n",
    "            # single process\n",
    "            indices.append(index)\n",
    "\n",
    "        raw_dataset_subset = raw_dataset[indices]\n",
    "        answers = raw_dataset_subset[\"answers\"]\n",
    "        lengths = raw_dataset_subset[\"length\"]\n",
    "        all_classes = []\n",
    "        score = scorer(dataset_name, preds, answers, all_classes)        \n",
    "        \n",
    "        logger.info(f\"{dataset_name}: {score}\")\n",
    "        metrics[dataset_name] = score\n",
    "\n",
    "        with open(makedirs(result_path), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps(score, ensure_ascii=False) + \"\\n\")\n",
    "            for index, pred in zip(indices, preds):\n",
    "                sample = raw_dataset[index]\n",
    "                del sample[\"context\"]\n",
    "                sample[\"pred\"] = pred\n",
    "                f.write(json.dumps(sample, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
